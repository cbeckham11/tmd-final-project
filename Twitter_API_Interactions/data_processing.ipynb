{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1 of the final project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json as js\n",
    "import requests\n",
    "import os\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "bookTitle = 'tenLessons'\n",
    "data = js.load(open(f'nytBestsellers2020/{bookTitle}/{bookTitle}Tweets/response1.json'))\n",
    "tweet_df = pd.DataFrame(data[\"data\"])\n",
    "\n",
    "#CHANGE THE RANGE\n",
    "for i in range(1, 2):\n",
    "    filepath = f'nytBestsellers2020/{bookTitle}/{bookTitle}Tweets/response{i}.json'\n",
    "    data = js.load(open(filepath))\n",
    "    new_df = pd.DataFrame(data[\"data\"])\n",
    "    tweet_df = pd.concat([new_df, tweet_df])\n",
    "\n",
    "print(len(tweet_df))\n",
    "print(len(tweet_df['author_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('authors.txt', 'w') as f:\n",
    "    pd.DataFrame(tweet_df['author_id'].unique()).to_csv(f, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('authors.txt', 'r') as f:\n",
    "    contents = f.readlines()\n",
    "    contents = [line.strip() for line in contents]\n",
    "\n",
    "# create a comma-separated string of 100 values at a time\n",
    "with open('author_chunks.txt', 'w') as f_out:\n",
    "    for i in range(0, len(contents), 100):\n",
    "        chunk = contents[i:i+100]\n",
    "        csv_string = \",\".join(chunk)\n",
    "\n",
    "        # write the csv string to the output file\n",
    "        f_out.write(csv_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = js.load(open(f'nytBestsellers2020/{bookTitle}/{bookTitle}Users/response_user0.json'))\n",
    "user_df = pd.DataFrame(data[\"data\"])\n",
    "\n",
    "#CHANGE THE RANGE\n",
    "for i in range(0, 1):\n",
    "    filepath =f'nytBestsellers2020/{bookTitle}/{bookTitle}Users/response_user{i}.json'\n",
    "    data = js.load(open(filepath))\n",
    "    new_df = pd.DataFrame(data[\"data\"])\n",
    "    user_df = pd.concat([new_df, user_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('non_null_locations.txt', 'w') as f:\n",
    "    user_df[user_df['location'].notnull()==True]['location'].to_csv(f, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('non_null_locations.txt', 'r') as f_in, open('non_null_locations_encoded.txt', 'w') as f_out:\n",
    "    for (i, line) in enumerate(f_in):\n",
    "        clean_line = line.replace(\",\", \"\")\n",
    "        clean_line = clean_line.replace(\"'\", \"\")\n",
    "        clean_line = clean_line.replace(\".\", \"\")\n",
    "        encoded_line = urllib.parse.quote(clean_line.strip())\n",
    "        f_out.write(encoded_line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2d1937eaf42a33f6bad7128f9b80658bbb1685d32bc9da03c4702cc46b61d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
